{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents/es_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from llama_index.core.workflow import Event,StartEvent,StopEvent,Workflow,step, Context\n",
    "\n",
    "from typing import Any\n",
    "from typing import List\n",
    "from llama_index.core.memory import ChatMemoryBuffer\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from multi_agent_llms.utils.opensearch_utils import recursive_literal_eval\n",
    "from multi_agent_llms.utils.agent_prompts import QueryDetails\n",
    "from multi_agent_llms.utils.agent_prompts import ResponseSynthesizer\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import mlflow\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class UserState(BaseModel):\n",
    "    user_query:str = Field(description='User query')\n",
    "    schema_selector_error_lists:list=Field(default=[])\n",
    "    query_execution_error_lists: list=Field(default=[])\n",
    "    validation_error_list:list=Field(default=[])\n",
    "    error_lists:list=Field(default=[])\n",
    "    schema_selector_response:object=Field(default=None)\n",
    "    query_generator_response:object = Field(default=None)\n",
    "    query_validator_response:object = Field(default=None)\n",
    "    query_response_synthesis:object = Field(default=None)\n",
    "    query_validation_run_count:int=0\n",
    "    query_run_count:int=0\n",
    "    es_response:dict=dict()\n",
    "    exited_with_error:bool=False\n",
    "    exited_stage:str=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class QueryState(BaseModel):\n",
    "    query:str|dict = Field(description='ES Query')\n",
    "    query_creation_stage:str = Field(default=None,description='Where the query was created')\n",
    "    query_creation_timestamp:str = Field(default=str(pd.Timestamp.utcnow()),description='ES Query creation timestamp')\n",
    "    rejection_timestamp:str = Field(default=None,description='Rejection timestamp')\n",
    "    cot:List[str] = Field(default=[], description='ES Query')\n",
    "    rejection_reasons:List[str] = Field(default=[], description='Reasons for rejection')\n",
    "    validation_score:float = Field(default=None,description='validation score')\n",
    "    status:bool = Field(default=False,description='Status of query execution or validation')\n",
    "    rejection_stage:str = Field(default='',description='Stage where the query was rejected')\n",
    "    query_id:int = Field(default=None,description='Query Number')\n",
    "    run_id:str = Field(default='default',description='Run Id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLFlowLamaIndexLogger(object):\n",
    "    def __init__(self, session_id, experiment_name:str):\n",
    "        self.session_id = session_id\n",
    "        self.run_id = self.get_run_id()\n",
    "        self.experiment_name = experiment_name\n",
    "    \n",
    "    def get_run_id(self):\n",
    "        if self.session_id is not None:\n",
    "            return f'{self.session_id}_{str(pd.Timestamp.now())}'\n",
    "        else:\n",
    "            return f'default_{str(pd.Timestamp.now())}'\n",
    "    \n",
    "    def start_mlflow_logging(self):\n",
    "        mlflow.set_experiment(self.experiment_name)\n",
    "        mlflow.start_run()\n",
    "        mlflow.set_tag(\"mlflow.runName\", self.run_id) \n",
    "        mlflow.llama_index.autolog(disable=False)\n",
    "    \n",
    "    def end_mlflow_logging(self):\n",
    "        mlflow.llama_index.autolog(disable=True)\n",
    "    \n",
    "    def log_json_artifact(self, file_name:str, data):    \n",
    "        # Optionally, you can log it as an artifact (if you prefer saving it as a file)\n",
    "        with open(f\"{file_name}.json\", \"w\") as f:\n",
    "            json.dump(data, f)\n",
    "        mlflow.log_artifact(f\"{file_name}.json\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MlFlowLamaIndexESAgentLoggerDataPrepare(object):\n",
    "    def __init__(self, run_id):\n",
    "        self.run_id:str = run_id\n",
    "        self.current_query_state:QueryState = None\n",
    "        self.query_list:List[QueryState] = []\n",
    "        \n",
    "    def initialize_query_state(self, data, stage):\n",
    "        self.current_query_state= QueryState(query=data.query, \n",
    "                                             cot=data.cot, \n",
    "                                            query_creation_stage=stage, \n",
    "                                            query_creation_timestamp=str(pd.Timestamp.utcnow())\n",
    "                                            )\n",
    "\n",
    "        \n",
    "    \n",
    "    def update_variables_on_rejection(self, stage:str, rejection_reasons:List[str]):\n",
    "        self.current_query_state.rejection_stage = stage\n",
    "        self.current_query_state.run_id = self.run_id\n",
    "        self.current_query_state.status = False\n",
    "        self.current_query_state.rejection_reasons = rejection_reasons\n",
    "        self.current_query_state.query_id = len(self.query_list)+1\n",
    "        self.current_query_state.rejection_timestamp = str(pd.Timestamp.utcnow())\n",
    "\n",
    "        self.query_list.append(self.current_query_state.model_dump())\n",
    "        self.current_query_state = None \n",
    "    \n",
    "    def update_variables_on_sucess(self):\n",
    "        self.current_query_state.status = True\n",
    "        self.current_query_state.run_id = self.run_id\n",
    "        self.current_query_state.query_id = len(self.query_list)+1\n",
    "        self.query_list.append(self.current_query_state.model_dump())\n",
    "        self.current_query_state = None \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class EstablishEnvEvent(Event):\n",
    "    pass\n",
    "\n",
    "class SchemaSelectorEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryGeneratorEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryValidatorEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryRunCorrectionEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryValidationCorrectionEvent(Event):\n",
    "    pass\n",
    "\n",
    "class QueryRunEvent(Event):\n",
    "    pass\n",
    "\n",
    "class ResultInferenceEvent(Event):\n",
    "    pass\n",
    "\n",
    "class ContextInferenceEvent(Event):\n",
    "    \"\"\"\n",
    "    Event to be triggred when the solution is found in the context and doesnot need to query ES\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "class ErrorEvent(Event):\n",
    "    error_stage:str\n",
    "\n",
    "class ErrorCompleteEvent(Event):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ElastiSearchcAgent(Workflow):\n",
    "    \"\"\"\n",
    "    Multi-agent to query ES instance\n",
    "    1. The agent will create and run the query against an es instance\n",
    "    2. Actor-critic paradigm utilzed to improve system relaiability. LLM as judge\n",
    "    3. LLM used generate inferences from es results\n",
    "    \"\"\"\n",
    "    def __init__(self, llm:object, agent_dict:dict, schema_dict:dict, opensearch_client:object,city=str,\n",
    "                 max_errors:int=1, session_id:str=None,*args: Any, **kwargs: Any)->None:\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.memory = ChatMemoryBuffer.from_defaults(llm=llm)\n",
    "        self.llm = llm\n",
    "        self.agent_dict=agent_dict\n",
    "        self.error_dict = dict()\n",
    "        self.max_errors = max_errors\n",
    "        self.schema_dict = schema_dict\n",
    "        self.opensearch_client = opensearch_client\n",
    "        self.city=city\n",
    "        self.session_id = session_id\n",
    "\n",
    "        \n",
    "\n",
    "    def run_agent(self, agent, agent_prompt):\n",
    "        sllm = self.llm.as_structured_llm(agent.output_class)\n",
    "        response = sllm.complete(agent_prompt)\n",
    "        response = recursive_literal_eval(response.text)\n",
    "        return agent.output_class(**response)\n",
    "\n",
    "    def handle_error(self, stage, error):\n",
    "        print('*'*50)\n",
    "        print('Ecountered error in ', stage)\n",
    "        print(error)\n",
    "        self.user_state.schema_selector_error_lists.append(error.__str__)\n",
    "\n",
    "    @step\n",
    "    async def handle_establish_env(self, ctx: Context,  ev:StartEvent) -> EstablishEnvEvent:\n",
    "        \"\"\"\n",
    "        Establish user state and execution env\n",
    "        \"\"\"\n",
    "        self.logger = MLFlowLamaIndexLogger(session_id=self.session_id, experiment_name=\"ES Agent Workflow Tutorial\")\n",
    "        self.logger.start_mlflow_logging()\n",
    "        \n",
    "        self.logger_data_prepare = MlFlowLamaIndexESAgentLoggerDataPrepare(run_id=self.logger.run_id)\n",
    "        mlflow.log_param('user_query', ev.query)\n",
    "        assert self.llm is not None\n",
    "\n",
    "        # hold the user state for the current querx\n",
    "        self.user_state = UserState(user_query=ev.query)\n",
    "        return EstablishEnvEvent()\n",
    "\n",
    "    @step\n",
    "    async def handle_schema_selector_event(self, ctx: Context,  ev:EstablishEnvEvent)->SchemaSelectorEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Select the indexes to answer the user query\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (EstablishEnvEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            SchemaSelectorEvent: when we have sucessfully selected relevant events and forward to query generator\n",
    "            ErrorEvent: in case of an error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            agent = self.agent_dict['schema_selector']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                    schema_str=self.schema_dict\n",
    "                                                    )\n",
    "            self.user_state.schema_selector_response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            selected_schemas = [x.variable_name for x in self.user_state.schema_selector_response.indexes]\n",
    "            mlflow.log_param(key='selected schemas', value=selected_schemas)\n",
    "            return SchemaSelectorEvent()\n",
    "        except Exception as e:\n",
    "            self.handle_error('schema selector', e)\n",
    "            return ErrorEvent(error_stage='schema selection')\n",
    "\n",
    "    @step\n",
    "    async def handle_query_generator(self, ctx: Context,  ev:SchemaSelectorEvent)->QueryGeneratorEvent|ErrorEvent|ContextInferenceEvent:\n",
    "        \"\"\"\n",
    "        Use the schema selectors to generate es query\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (SchemaSelectorEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            QueryGeneratorEvent: successful generation of query and forward it to query validation\n",
    "            ErrorEvent: in case of an error\n",
    "            ContextInferenceEvent: can be answered without any es query\n",
    "        \"\"\"\n",
    "        schema_response = self.user_state.schema_selector_response\n",
    "        try:\n",
    "            agent = self.agent_dict['query_generator']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                        schema_str=schema_response,\n",
    "                                                        input_str=QueryDetails.model_json_schema()\n",
    "                                                            )\n",
    "            response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            self.user_state.query_generator_response = response\n",
    "\n",
    "            if len(self.user_state.query_generator_response.context_solution)>0 and len(self.user_state.query_generator_response.query)==0:\n",
    "                self.query_state = QueryState(query='Context Inference', cot=response.cot)\n",
    "                return ContextInferenceEvent()\n",
    "            \n",
    "            elif len(self.user_state.query_generator_response.query)==0 and len(self.user_state.query_generator_response.context_solution)==0:\n",
    "                return ErrorEvent(error_stage='query generator')\n",
    "        \n",
    "            self.logger_data_prepare.initialize_query_state(data=response, stage='query generator')\n",
    "            \n",
    "            return QueryGeneratorEvent()\n",
    "        except Exception as e:\n",
    "            self.handle_error('query generator', e)\n",
    "            return ErrorEvent(error_stage='query generator')\n",
    "    \n",
    "    @step\n",
    "    async def handle_context_inference_generator(self, ctx: Context,  ev:ContextInferenceEvent)->ResultInferenceEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Handle when query can be answered without es help\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (ContextInferenceEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            ResultInferenceEvent: update the resposne and finish sucessfull execution\n",
    "            ErrorEvent: in case of error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            response = ResponseSynthesizer(user_query=self.user_state.user_query,\n",
    "                                           response=self.user_state.query_generator_response.context_solution\n",
    "                                           )\n",
    "            self.user_state.query_response_synthesis = response\n",
    "            return ResultInferenceEvent()\n",
    "        except Exception as e:\n",
    "            self.handle_error('Context Inference', e)\n",
    "            return ErrorEvent(error_stage='Context Inference event')\n",
    "\n",
    "    @step\n",
    "    async def handle_query_validator_event(self, ctx: Context,  ev:QueryGeneratorEvent)->QueryValidatorEvent|ErrorEvent|QueryValidationCorrectionEvent:\n",
    "        \"\"\"\n",
    "        Symenatic validaton of the query and the user request\n",
    "        LLM as a judge with the critic model\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (QueryGeneratorEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            QueryValidatorEvent: sucessful validation forward to runner\n",
    "            ErrorEvent: in case of error\n",
    "            QueryValidationCorrectionEvent: correct the query incase the threshold is not statisfied\n",
    "        \"\"\"\n",
    "        try:\n",
    "            print('*'*50)\n",
    "            print('Running Query evalution no:', self.user_state.query_validation_run_count)\n",
    "            display(self.user_state.query_generator_response.query)\n",
    "\n",
    "            agent = self.agent_dict['query_validator']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                        schema_str=self.user_state.schema_selector_response.indexes,\n",
    "                                                        input_str=QueryDetails.model_json_schema(),\n",
    "                                                        es_query=self.user_state.query_generator_response.query\n",
    "                                                            )\n",
    "            response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            self.user_state.query_validator_response =  response\n",
    "            self.logger_data_prepare.current_query_state.validation_score = response.query_score\n",
    "            \n",
    "            assert self.user_state.query_validation_run_count < self.max_errors, \"maximum iterations for the query validator reached\"\n",
    "            if response.query_score < .9:\n",
    "                self.logger_data_prepare.update_variables_on_rejection(stage='query validation', \n",
    "                                                                       rejection_reasons=response.reason\n",
    "                                                                       )\n",
    "                \n",
    "                self.user_state.query_validation_run_count += 1\n",
    "                self.user_state.validation_error_list.append(self.user_state.query_validator_response.reason)\n",
    "                print('Failed Query evalution :', self.user_state.query_validator_response.reason)\n",
    "                return QueryValidationCorrectionEvent()\n",
    "            \n",
    "            self.user_state.query_validation_run_count = 0\n",
    "            return QueryValidatorEvent()\n",
    "        \n",
    "        except Exception as e:\n",
    "            self.logger_data_prepare.update_variables_on_rejection(stage='query validation', \n",
    "                                                                       rejection_reasons=[e.__str__]\n",
    "                                                                       )\n",
    "            self.handle_error('Query Validations', e)\n",
    "            return ErrorEvent(error_stage='query validation')\n",
    "    \n",
    "    @step\n",
    "    async def handle_query_run_event(self, ctx: Context,  ev:QueryValidatorEvent)->QueryRunEvent|QueryRunCorrectionEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Execute query against ES instance\n",
    "\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (QueryValidatorEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            QueryRunEvent: sucessful execution of query , foraward to result inference\n",
    "            QueryRunCorrectionEvent: correct faulty query by incorporating the error information\n",
    "            ErrorEvent: incase of error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            start_date = self.user_state.query_generator_response.start_date\n",
    "            end_date = self.user_state.query_generator_response.end_date\n",
    "            if 'now' in end_date:\n",
    "                end_date = pd.Timestamp.now()\n",
    "                start_date = end_date - pd.Timedelta(start_date.split('-')[1].split('/')[0])\n",
    "\n",
    "            query = self.user_state.query_generator_response.query\n",
    "            print('*'*50)\n",
    "            print('Running the query')\n",
    "            display(query)\n",
    "\n",
    "            if len(query)>0:\n",
    "                if start_date in ['', '*', None] and end_date in ['', '*', None]:\n",
    "                    search_indexes = [self.opensearch_client.get_index(i.variable_name, self.city,None) \n",
    "                                    for i in self.user_state.schema_selector_response.indexes]\n",
    "                else:\n",
    "                    search_indexes = [self.opensearch_client.get_index(i.variable_name, self.city,date) \n",
    "                                    for date in pd.date_range(start_date, end_date, freq='MS') \n",
    "                                        for i in self.user_state.schema_selector_response.indexes]\n",
    "                    \n",
    "                print('going to fetch information from ', search_indexes)\n",
    "                self.user_state.es_response = self.opensearch_client.get_data(query=query, opensearch_index=search_indexes)\n",
    "                if len(self.user_state.es_response)==0:\n",
    "                    self.user_state.error_lists.append('No ES data found')\n",
    "                    self.logger_data_prepare.update_variables_on_rejection(stage='query run', \n",
    "                                                                   rejection_reasons=['No data found']\n",
    "                                                                  )\n",
    "                    return ErrorEvent(error_stage='query run')\n",
    "\n",
    "                self.user_state.query_run_count = 0\n",
    "                return QueryRunEvent()        \n",
    "        except Exception as e:\n",
    "            self.logger_data_prepare.update_variables_on_rejection(stage='query run', \n",
    "                                                                   rejection_reasons=[e.__str__]\n",
    "                                                                  )\n",
    "            self.handle_error('Query Runner', e)\n",
    "            self.user_state.query_execution_error_lists.append(e.__str__)\n",
    "            self.user_state.query_run_count += 1\n",
    "            if self.user_state.query_run_count < self.max_errors:\n",
    "                return QueryRunCorrectionEvent()\n",
    "            return ErrorEvent()\n",
    "\n",
    "    @step\n",
    "    async def handle_query_validation_correction_event(self, ctx: Context,  ev:QueryValidationCorrectionEvent)->QueryGeneratorEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Correct the symantic role of the query\n",
    "\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (QueryValidationCorrectionEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            QueryGeneratorEvent: on successful query correction, send it to the query validator\n",
    "            ErrorEvent: in case of error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # update the log with the rejection\n",
    "            agent = self.agent_dict['query_corrector']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                        schema_str=self.user_state.schema_selector_response.indexes,\n",
    "                                                        input_str=QueryDetails.model_json_schema(),\n",
    "                                                        es_query=self.user_state.query_generator_response.query,\n",
    "                                                        error_list=self.user_state.validation_error_list\n",
    "                                                            )\n",
    "            response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            self.user_state.query_generator_response = response\n",
    "            self.logger_data_prepare.initialize_query_state(data=response, stage='query validation correction')\n",
    "            return QueryGeneratorEvent()        \n",
    "        except Exception as e:\n",
    "            self.handle_error('Query Validations Correction', e)\n",
    "            return ErrorEvent(error_stage='query validation correction')\n",
    "    \n",
    "    @step\n",
    "    async def handle_query_run_correction_event(self, ctx: Context,  ev:QueryRunCorrectionEvent)->QueryGeneratorEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Correct query by incorporating its run time errors\n",
    "\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (QueryRunCorrectionEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            QueryGeneratorEvent: send to the query validation for symantic validation\n",
    "            ErrorEvent: on error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            agent = self.agent_dict['query_corrector']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                        schema_str=self.user_state.schema_selector_response.indexes,\n",
    "                                                        input_str=QueryDetails.model_json_schema(),\n",
    "                                                        es_query=self.user_state.query_generator_response.query,\n",
    "                                                        error_list=self.user_state.query_execution_error_lists\n",
    "                                                            )\n",
    "            response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            self.user_state.query_generator_response = response\n",
    "            self.logger_data_prepare.initialize_query_state(data=response, stage='query run correction')\n",
    "            return QueryGeneratorEvent()        \n",
    "        except Exception as e:\n",
    "            self.handle_error('Query Run Correction', e)\n",
    "            return ErrorEvent(error_stage='query run correction')\n",
    "\n",
    "    @step\n",
    "    async def handle_result_inference_event(self, ctx: Context,  ev:QueryRunEvent)->ResultInferenceEvent|ErrorEvent:\n",
    "        \"\"\"\n",
    "        Prepare the inference data using LLM call with the es results\n",
    "        Args:\n",
    "            ctx (Context): _description_\n",
    "            ev (QueryRunEvent): _description_\n",
    "\n",
    "        Returns:\n",
    "            ResultInferenceEvent: sucessful inference generation\n",
    "            ErrorEvent: on error\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.logger_data_prepare.update_variables_on_sucess()\n",
    "            query = self.user_state.query_generator_response.query\n",
    "            agg_dict_bool = True if 'aggs' in query or 'aggs' in  query.get('query') else False\n",
    "            query_dict_bool = True if 'query' in query else False\n",
    "\n",
    "            results = self.user_state.es_response \n",
    "\n",
    "            if agg_dict_bool:\n",
    "                results = results['aggregations']\n",
    "            else:\n",
    "                results = pd.json_normalize(pd.DataFrame(results.get('hits').get('hits'))['_source'])\n",
    "\n",
    "            agent = self.agent_dict['response_synthesizer']\n",
    "            agent_prompt = agent.agent_prompt.format(query_str=self.user_state.user_query,\n",
    "                                                    schema_str=self.user_state.schema_selector_response.indexes,\n",
    "                                                    results=results\n",
    "                                                                )\n",
    "            response = self.run_agent(agent=agent, agent_prompt=agent_prompt)\n",
    "            self.user_state.query_response_synthesis = response\n",
    "            return ResultInferenceEvent()\n",
    "        except Exception as e:\n",
    "            self.handle_error('Result Inference', e)\n",
    "            return ErrorEvent(error_stage='result inference')\n",
    "\n",
    "    @step\n",
    "    async def handle_error_event(self, ctx: Context,  ev:ErrorEvent)->ErrorCompleteEvent:\n",
    "        self.user_state.exited_stage = ev.error_stage\n",
    "        self.user_state.exited_with_error = True\n",
    "        return ErrorCompleteEvent()\n",
    "\n",
    "    @step\n",
    "    async def handle_stop_event(self, ctx: Context,  ev:ResultInferenceEvent|ErrorCompleteEvent)->StopEvent:\n",
    "        mlflow.log_param('test_key',self.logger_data_prepare.query_list)\n",
    "        self.logger.log_json_artifact(file_name='test_artifact', data=self.logger_data_prepare.query_list)\n",
    "        self.logger.end_mlflow_logging()\n",
    "        return StopEvent(self.user_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.utils.workflow import draw_all_possible_flows\n",
    "# workflow = ElastiSearchcAgent(agent_dict=None, llm='', schema_dict=None,\n",
    "#                               opensearch_client=None, city=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
